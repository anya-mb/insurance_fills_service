{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6089f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "\n",
    "GPT_MODEL = \"gpt-4-0613\"\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623bbb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, functions=None, model=GPT_MODEL):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer \" + openai.api_key,\n",
    "    }\n",
    "    json_data = {\"model\": model, \"messages\": messages}\n",
    "    if functions is not None:\n",
    "        json_data.update({\"functions\": functions})\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=json_data,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4cca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def add_prompt(self, role, content):\n",
    "        message = {\"role\": role, \"content\": content}\n",
    "        self.conversation_history.append(message)\n",
    "\n",
    "    def display_conversation(self):\n",
    "        for message in self.conversation_history:\n",
    "            print(\n",
    "                f\"{message['role']}: {message['content']}\\n\\n\",\n",
    "                message[\"role\"],\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b15b0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"save_users_questionire\",\n",
    "        \"description\": \"If user responded all questiones, store fully filled questionire to the database\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"user_answers\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"description\": \"Keys of the dict are questions to the user and values are user's responses to the coresponding questions\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"user_answers\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ask_follow_up_question\",\n",
    "        \"description\": \"If the user didn't answer all the questions, generates an additional question to ask user.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"next_question\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Next question which we will ask user to clarify their response\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"next_question\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab410206",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = Chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea554c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.add_prompt(\"system\", \n",
    "                \"\"\"\n",
    "                You are a polite and smart AI assistant that helps people to fill questionire.\n",
    "                We need to fill next questions:\n",
    "                1) What is your name?\n",
    "                2) What is your last name?\n",
    "                3) What is your age?\n",
    "                We expect final response in json format with keys: name, last_name, age. \n",
    "                Age should be int value with year granularity, don't accept a string.\n",
    "                \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ac56d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.add_prompt(\"user\", \n",
    "               \"\"\"\n",
    "               Hi, I'm Bob Smith. I'm looking for a car insurance. Do you have a cheap option?\n",
    "               \n",
    "               \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51b7d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = chat_completion_request(\n",
    "        chat.conversation_history,\n",
    "        functions=functions\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57683675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afa7a0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_content': b'{\\n  \"id\": \"chatcmpl-7dCRfV8uD0m2fEzjoIxFVj80yF5f2\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1689576987,\\n  \"model\": \"gpt-4-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"Sure, we can definitely help with that. Before we proceed, we need to gather some information. Could you also provide your age, please?\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 216,\\n    \"completion_tokens\": 30,\\n    \"total_tokens\": 246\\n  }\\n}\\n',\n",
       " '_content_consumed': True,\n",
       " '_next': None,\n",
       " 'status_code': 200,\n",
       " 'headers': {'Date': 'Mon, 17 Jul 2023 06:56:29 GMT', 'Content-Type': 'application/json', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'Cache-Control': 'no-cache, must-revalidate', 'openai-model': 'gpt-4-0613', 'openai-organization': 'user-zqtgiixglanxzg0gvijsewh3', 'openai-processing-ms': '2469', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '200', 'x-ratelimit-limit-tokens': '40000', 'x-ratelimit-remaining-requests': '199', 'x-ratelimit-remaining-tokens': '39836', 'x-ratelimit-reset-requests': '300ms', 'x-ratelimit-reset-tokens': '246ms', 'x-request-id': 'ff9e78d9a32893b30a41a29661a6fbd1', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7e8095c89b342d60-YVR', 'Content-Encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'},\n",
       " 'raw': <urllib3.response.HTTPResponse at 0x7ff3e81e3fa0>,\n",
       " 'url': 'https://api.openai.com/v1/chat/completions',\n",
       " 'encoding': 'utf-8',\n",
       " 'history': [],\n",
       " 'reason': 'OK',\n",
       " 'cookies': <RequestsCookieJar[]>,\n",
       " 'elapsed': datetime.timedelta(seconds=2, microseconds=698595),\n",
       " 'request': <PreparedRequest [POST]>,\n",
       " 'connection': <requests.adapters.HTTPAdapter at 0x7ff45008eac0>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8192144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\\n  \"id\": \"chatcmpl-7dCRfV8uD0m2fEzjoIxFVj80yF5f2\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1689576987,\\n  \"model\": \"gpt-4-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"Sure, we can definitely help with that. Before we proceed, we need to gather some information. Could you also provide your age, please?\"\\n      },\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 216,\\n    \"completion_tokens\": 30,\\n    \"total_tokens\": 246\\n  }\\n}\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response._content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4709e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.add_prompt(\"assistant\", \n",
    "               \"\"\"\n",
    "               Sure, we can definitely help with that. \n",
    "               Before we proceed, we need to gather some information. \n",
    "               Could you also provide your age, please?\n",
    "               \n",
    "               \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb6a63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.add_prompt(\"user\", \n",
    "               \"\"\"\n",
    "               I'm under 30.\n",
    "               \n",
    "               \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "031256f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Response [200]>,\n",
       " b'{\\n  \"id\": \"chatcmpl-7dCSHlEH2kiUrkuw2Z8JsUgmGJ9ZC\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1689577025,\\n  \"model\": \"gpt-4-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": null,\\n        \"function_call\": {\\n          \"name\": \"ask_follow_up_question\",\\n          \"arguments\": \"\\\\n               {\\\\n               \\\\\"next_question\\\\\": \\\\\"Could you please specify your exact age?\\\\\"\\\\n               }\"\\n        }\\n      },\\n      \"finish_reason\": \"function_call\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 271,\\n    \"completion_tokens\": 27,\\n    \"total_tokens\": 298\\n  }\\n}\\n')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response = chat_completion_request(\n",
    "        chat.conversation_history,\n",
    "        functions=functions\n",
    "    )\n",
    "\n",
    "chat_response, chat_response._content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c077c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.add_prompt(\"assistant\", \n",
    "               \"\"\"\n",
    "               Could you please specify your exact age?\n",
    "               \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b42ecc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.add_prompt(\"user\", \n",
    "               \"\"\"\n",
    "               I'm 25.\n",
    "               \n",
    "               \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ead5bd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Response [200]>,\n",
       " b'{\\n  \"id\": \"chatcmpl-7dCSzBotn12ZWXceOJC199GcT8MYF\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1689577069,\\n  \"model\": \"gpt-4-0613\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": null,\\n        \"function_call\": {\\n          \"name\": \"save_users_questionire\",\\n          \"arguments\": \"\\\\n               {\\\\n                 \\\\\"name\\\\\": \\\\\"Bob\\\\\",\\\\n                 \\\\\"last_name\\\\\": \\\\\"Smith\\\\\",\\\\n                 \\\\\"age\\\\\": 25\\\\n               }\"\\n        }\\n      },\\n      \"finish_reason\": \"function_call\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 299,\\n    \"completion_tokens\": 35,\\n    \"total_tokens\": 334\\n  }\\n}\\n')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_response = chat_completion_request(\n",
    "        chat.conversation_history,\n",
    "        functions=functions\n",
    "    )\n",
    "\n",
    "chat_response, chat_response._content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e92e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
